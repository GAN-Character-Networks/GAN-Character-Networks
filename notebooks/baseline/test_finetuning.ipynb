{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertForTokenClassification, AutoTokenizer, pipeline\n",
    "model = CamembertForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\", return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "['▁<', 'PER', '>', '▁Jean', '-', 'Pierre', '▁Pap', 'in', '▁', '</', 'PER', '>', '▁dit', '▁à', '▁<', 'PER', '>', '▁Jean', '-', 'Paul', '▁E', 'lu', 'ard', '▁', '</', 'PER', '>', '▁qu', \"'\", 'il', '▁était', '▁gay', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"<PER> Jean-Pierre Papin </PER> dit à <PER> Jean-Paul Eluard </PER> qu'il était gay.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "inputs = tokenizer(phrase, return_tensors=\"pt\")\n",
    "#print(inputs)\n",
    "print(type(inputs))\n",
    "print(tokenizer.tokenize(phrase))\n",
    "logits = model(**inputs).logits\n",
    "labels = logits.argmax(-1)\n",
    "loss = model(**inputs, labels=labels).loss\n",
    "round(loss.item(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9991478,\n",
       "  'word': 'Jean-Pierre Papin',\n",
       "  'start': 5,\n",
       "  'end': 23},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9991401,\n",
       "  'word': 'Jean-Paul Eluard',\n",
       "  'start': 42,\n",
       "  'end': 59}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "nlp(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁<', 'PER', '>', '▁Jean', '-', 'Pierre', '▁Pap', 'in', '▁', '</', 'PER', '>', '▁dit', '▁à', '▁<', 'PER', '>', '▁Jean', '-', 'Paul', '▁E', 'lu', 'ard', '▁', '</', 'PER', '>', '▁qu', \"'\", 'il', '▁était', '▁gay', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(tokenizer.tokenize(phrase))\n",
    "# array = word_tokenize(phrase)\n",
    "# print(array)\n",
    "# for word in array:\n",
    "#     print(tokenizer.tokenize(word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
