{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vroom.NER import *\n",
    "from vroom.alias import *\n",
    "from vroom.baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"../data/kaggle/prelude_a_fondation/chapter_1.txt.preprocessed\"\n",
    "path = \"../../data/kaggle/prelude_a_fondation/chapter_1.txt.preprocessed\"\n",
    "entities, _ = get_entities_from_file(path)\n",
    "\n",
    "entities = [entity for sublist in entities for entity in sublist]\n",
    "\n",
    "\n",
    "# for entity in entities:\n",
    "#     print(entity[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cléon_ier—', 'seldon', 'sire', 'cléon'],\n",
       " ['empereur', 'empereurs'],\n",
       " ['hari_seldon'],\n",
       " ['eto_demerzel', 'demerzel'],\n",
       " ['lieutenant_alban_wellis'],\n",
       " ['wellis'],\n",
       " ['trantor'],\n",
       " ['hummin']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aliases_jaro_winkler(entities, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fuzzy done =====\n",
      "['CLÉON Ier—', 'Cléon']\n",
      "['Empereur', 'Empereurs']\n",
      "['Hari Seldon', 'Seldon']\n",
      "['Eto Demerzel', 'Demerzel']\n",
      "['Sire']\n",
      "['Lieutenant Alban Wellis', 'Wellis']\n",
      "['Trantor']\n",
      "['Hummin']\n"
     ]
    }
   ],
   "source": [
    "aliases = get_aliases_fuzzy_partial_token(entities, 90)\n",
    "print(\"===== Fuzzy done =====\")\n",
    "for alias in aliases:\n",
    "    print(alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fuzzy done =====\n",
      "['CLÉON Ier—', 'Cléon']\n",
      "['Empereur', 'Empereurs']\n",
      "['Hari Seldon', 'Seldon']\n",
      "['Eto Demerzel', 'Demerzel']\n",
      "['Sire']\n",
      "['Lieutenant Alban Wellis', 'Wellis']\n",
      "['Trantor']\n",
      "['Hummin']\n"
     ]
    }
   ],
   "source": [
    "aliases = get_aliases_fuzzy_partial_token(entities, 90)\n",
    "print(\"===== Fuzzy done =====\")\n",
    "for alias in aliases:\n",
    "    print(alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating aliases resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vroom.NER import *\n",
    "from vroom.metrics import evaluate\n",
    "import os\n",
    "\n",
    "unlabeled_chapter = os.path.join(\"../../data\", \"test_set\", \"prelude_a_fondation\", \"chapter_1.unlabeled\")\n",
    "labeled_chapter = os.path.join(\"../../data\", \"test_set\", \"prelude_a_fondation\", \"chapter_1.labeled\")\n",
    "\n",
    "entities, chunks = get_entities_from_file(unlabeled_chapter, device=\"cuda\")\n",
    "\n",
    "all_entities_names = []\n",
    "for chunk in entities: \n",
    "    all_entities_names += [\n",
    "        entity[\"word\"] for entity in chunk\n",
    "    ]\n",
    "entities = set(all_entities_names)\n",
    "\n",
    "unlabeled_text_tagged = tag_text_with_entities(unlabeled_chapter, entities)\n",
    "\n",
    "labeled_text_tagged = read_file(labeled_chapter)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def separate_words(text):\n",
    "    # Use regular expression to find words and punctuation, including special words like <PER> and </PERS>\n",
    "    words = re.findall(r'\\b\\w+\\b|[.,;!?<>/]+|<PER>|</PER>', text)\n",
    "    return words\n",
    "\n",
    "def merge_special_words(word_list):\n",
    "    merged_list = []\n",
    "    current_word = \"\"\n",
    "\n",
    "    for word in word_list:\n",
    "        if word in ['<', 'PER', '</', '>']:\n",
    "            current_word += word\n",
    "        else:\n",
    "            if current_word:\n",
    "                merged_list.append(current_word)\n",
    "                current_word = \"\"\n",
    "            merged_list.append(word)\n",
    "\n",
    "    if current_word:\n",
    "        merged_list.append(current_word)\n",
    "\n",
    "    return merged_list\n",
    "\n",
    "def get_positions_of_entities(text):\n",
    "    words = separate_words(text)\n",
    "    words = merge_special_words(words)\n",
    "    positions = {}\n",
    "    current_entity = []\n",
    "    current_entity_start = 0\n",
    "    current_entity_end = 0\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        if word == \"<PER>\":\n",
    "            current_entity = []\n",
    "            current_entity_start = i\n",
    "        elif word == \"</PER>\":\n",
    "            current_entity_end = i\n",
    "            positions[(current_entity_start, current_entity_end)] = ' '.join(current_entity)\n",
    "        else:\n",
    "            i += 1\n",
    "            current_entity.append(word)\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'CLÉON Ier'}, {'word': 'Empereur'}, {'word': 'Hari Seldon'}, {'word': 'Seldon'}, {'word': 'Cléon'}, {'word': 'Seldon'}, {'word': 'Cléon'}, {'word': 'Eto Demerzel'}, {'word': 'Cléon'}, {'word': 'Cléon'}, {'word': 'Demerzel'}, {'word': 'Hari Seldon'}, {'word': 'Cléon'}, {'word': 'Hari Seldon'}, {'word': 'Demerzel'}, {'word': 'Demerzel'}, {'word': 'Sire'}, {'word': 'Sire'}, {'word': 'Sire'}, {'word': 'Demerzel'}, {'word': 'l Empereur'}, {'word': 'Demerzel'}, {'word': 'Sire'}, {'word': 'Demerzel'}, {'word': 'Lieutenant Alban Wellis'}, {'word': 'Wellis'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'l Empereur'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Hari Seldon'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Hari Seldon'}, {'word': 'Seldon'}, {'word': 'Sire'}, {'word': 'Seldon'}, {'word': 'l empereur Cléon'}, {'word': 'Cléon'}, {'word': 'Seldon'}, {'word': 'L Empereur'}, {'word': 'Seldon'}, {'word': 'L Empereur'}, {'word': 'L Empereur'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'Cléon'}, {'word': 'Cléon'}, {'word': 'Cléon'}, {'word': 'Cléon'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'l Empereur'}, {'word': 'Seldon'}, {'word': 'Cléon'}, {'word': 'Seldon'}, {'word': 'Sire'}, {'word': 'Cléon'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'Cléon'}, {'word': 'Seldon'}, {'word': 'Cléon'}, {'word': 'Sire'}, {'word': 'Demerzel'}, {'word': 'Sire'}, {'word': 'Sire'}, {'word': 'Demerzel'}, {'word': 'Cléon'}, {'word': 'Sire'}, {'word': 'l Empereur'}, {'word': 'Seldon'}, {'word': 'Demerzel'}, {'word': 'Sire'}, {'word': 'Demerzel'}, {'word': 'Cléon'}, {'word': 'Demerzel'}, {'word': 'Sire'}, {'word': 'Demerzel'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'l Empereur'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'Hummin'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'Seldon'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'Seldon'}, {'word': 'l Empereur'}, {'word': 'Cléon'}, {'word': 'Seldon'}, {'word': 'Hummin'}, {'word': 'Eto Demerzel'}, {'word': 'Eto Demerzel'}]\n"
     ]
    }
   ],
   "source": [
    "entities_raw = get_positions_of_entities(labeled_text_tagged)\n",
    "entities = []\n",
    "for entity in entities_raw:\n",
    "    if entities_raw[entity] not in entities:\n",
    "        entities.append({\"word\": entities_raw[entity]})\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating aliases resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def calculate_alias_metrics(baseline_aliases, test_aliases):\n",
    "    # Flatten both baseline and test lists to sets for easy comparison\n",
    "    baseline_set = {alias for aliases in baseline_aliases for alias in aliases}\n",
    "    test_set = {alias for aliases in test_aliases for alias in aliases}\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives = len(baseline_set.intersection(test_set))\n",
    "    false_positives = len(test_set.difference(baseline_set))\n",
    "    false_negatives = len(baseline_set.difference(test_set))\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = true_positives / len(baseline_set.union(test_set))\n",
    "\n",
    "    # Create a dictionary to store the measurements\n",
    "    measurements = {\n",
    "        \"true_positive\": true_positives,\n",
    "        \"false_positive\": false_positives,\n",
    "        \"false_negative\": false_negatives,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLÉON Ier', ' Empereur', ' Cléon', ' Sire', \" l'Empereur\", \" l'empereur Cléon\"]\n",
      "['Hari Seldon', ' Seldon']\n",
      "['Eto Demerzel', ' Demerzel']\n",
      "['Lieutenant Alban Wellis', ' Wellis']\n",
      "['Hummin']\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../data/test_set/prelude_a_fondation/chapter_1.aliases'\n",
    "\n",
    "baseline_aliases = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        elements = line.strip().split(',')\n",
    "        baseline_aliases.append(elements)\n",
    "\n",
    "for alias in baseline_aliases:\n",
    "    print(alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fuzzy done =====\n",
      "['CLÉON Ier', 'l empereur Cléon', 'Cléon']\n",
      "['Empereur', 'l Empereur']\n",
      "['Hari Seldon', 'Seldon']\n",
      "['Eto Demerzel', 'Demerzel']\n",
      "['Sire']\n",
      "['Lieutenant Alban Wellis', 'Wellis']\n",
      "['Hummin']\n",
      "True_positive: 5\n",
      "False_positive: 8\n",
      "False_negative: 8\n",
      "Precision: 0.38461538461538464\n",
      "Recall: 0.38461538461538464\n",
      "F1_score: 0.38461538461538464\n",
      "Accuracy: 0.23809523809523808\n"
     ]
    }
   ],
   "source": [
    "aliases = get_aliases_fuzzy_partial_token(entities, 90)\n",
    "print(\"===== Fuzzy done =====\")\n",
    "for alias in aliases:\n",
    "    print(alias)\n",
    "\n",
    "results = calculate_alias_metrics(baseline_aliases, aliases)\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric.capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fuzzy done =====\n",
      "['CLÉON Ier', 'l empereur Cléon', 'Cléon']\n",
      "['Empereur', 'l Empereur']\n",
      "['Hari Seldon', 'Seldon']\n",
      "['Eto Demerzel', 'Demerzel']\n",
      "['Sire']\n",
      "['Lieutenant Alban Wellis', 'Wellis']\n",
      "['Hummin']\n",
      "True_positive: 5\n",
      "False_positive: 8\n",
      "False_negative: 8\n",
      "Precision: 0.38461538461538464\n",
      "Recall: 0.38461538461538464\n",
      "F1_score: 0.38461538461538464\n",
      "Accuracy: 0.23809523809523808\n"
     ]
    }
   ],
   "source": [
    "aliases = get_aliases_fuzzy_partial_token(entities, 90)\n",
    "print(\"===== Fuzzy done =====\")\n",
    "for alias in aliases:\n",
    "    print(alias)\n",
    "\n",
    "results = calculate_alias_metrics(baseline_aliases, aliases)\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric.capitalize()}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
